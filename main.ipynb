{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GHhNTfWx0AGu",
    "outputId": "3cd883b2-2764-43e0-91ce-b28fb95f9d8f"
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "import numpy as np\n",
    "from helpers import *\n",
    "from methods import *\n",
    "from process_data import *\n",
    "from crossvalidation import *\n",
    "from select_parameter import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "seed=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJdJ20A-0AG1"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VNKVzVCh0B2g"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile \n",
    "  \n",
    "# # specifying the zip file name \n",
    "file_name = 'Data/test.csv.zip'\n",
    "  \n",
    "# opening the zip file in READ mode \n",
    "with ZipFile(file_name, 'r') as zip: \n",
    "    zip.extractall('Data/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dIS5My0U0AG1"
   },
   "outputs": [],
   "source": [
    "y, tX, ids = load_csv_data('Data/train.csv')\n",
    "_, tX_test, ids_test = load_csv_data('Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85667\n",
      "164333\n",
      "(250000,) (250000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.307776"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = np.ones(tX.shape[0])\n",
    "\n",
    "print(list(y[tX[:,4]<46]).count(1))\n",
    "print(list(y[tX[:,4]<46]).count(-1))\n",
    "ypred[tX[:,4]>3.2]=-1\n",
    "print(ypred.shape,y.shape)\n",
    "\n",
    "compute_accuracy(ypred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7448580264830402"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain= tX[tX[:,22]==0]\n",
    "ypred = -np.ones(xtrain.shape[0])\n",
    "ytrain=  y[tX[:,22]==0]\n",
    "#ypred[xtrain[:,1]<27]=1\n",
    "compute_accuracy(ypred, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwCwFsOGIdSe",
    "outputId": "54cb8c59-8402-486b-cfd6-7bedeca3f354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99913 77544 50379 22164\n"
     ]
    }
   ],
   "source": [
    "c1=np.count_nonzero(tX[:,22]==0)\n",
    "c2=np.count_nonzero(tX[:,22]==1)\n",
    "c3=np.count_nonzero(tX[:,22]==2)\n",
    "c4=np.count_nonzero(tX[:,22]==3)\n",
    "\n",
    "print(c1,c2,c3,c4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGxjbAte0AG6"
   },
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhDrrEpc0AG7"
   },
   "source": [
    "## 1. Least Squares with Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-C5gQC_0AG7"
   },
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yMTilRb0AG8",
    "outputId": "2e810048-012d-4944-da60-96ffdeee0a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Training accuracy: 0.780448 / Test accuracy : 0.781016\n",
      "1 - Training accuracy: 0.779968 / Test accuracy : 0.778256\n",
      "\n",
      "Average test accuracy: 0.779636\n",
      "Variance test accuracy: 0.000002\n",
      "Min test accuracy: 0.778256\n",
      "Max test accuracy: 0.781016\n"
     ]
    }
   ],
   "source": [
    "# Degree polynomial expansion\n",
    "degrees = [10,10,10,10]\n",
    "\n",
    "# Model parameters\n",
    "max_iters = 5000\n",
    "gamma = 0.005\n",
    "\n",
    "\n",
    "# Split data in k-fold\n",
    "k_fold = 2\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    acc_train, acc_test = cross_validation(y, tX, least_squares_GD, _, k_indices, k, degrees, alpha,\n",
    "                                           max_iters=max_iters, gamma=gamma)\n",
    "    accs_train.append(acc_train)\n",
    "    accs_test.append(acc_test)\n",
    "    \n",
    "for i in range(len(accs_train)):\n",
    "    print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (i, accs_train[i], accs_test[i]))\n",
    "\n",
    "print(\"\\nAverage test accuracy: %f\" % np.mean(accs_test))\n",
    "print(\"Variance test accuracy: %f\" % np.var(accs_test))\n",
    "print(\"Min test accuracy: %f\" % np.min(accs_test))\n",
    "print(\"Max test accuracy: %f\" % np.max(accs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkDIXO5f0AHD"
   },
   "source": [
    "## 2. Least Squares with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zHFA3AM0AHE"
   },
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMfrUMhn0AHF"
   },
   "outputs": [],
   "source": [
    "# Degree polynomial expansion\n",
    "degrees = [10,10,10,10]\n",
    "\n",
    "# Model parameters\n",
    "max_iters = 1000\n",
    "gamma = 0.005\n",
    "batch_size=1\n",
    "\n",
    "\n",
    "# Split data in k-fold\n",
    "k_fold = 2\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    acc_train, acc_test = cross_validation(y, tX, least_squares_SGD, _, k_indices, k, degrees, alpha, \n",
    "                                           max_iters=max_iters, gamma=gamma, batch_size=batch_size)\n",
    "    accs_train.append(acc_train)\n",
    "    accs_test.append(acc_test)\n",
    "    \n",
    "for i in range(len(accs_train)):\n",
    "    print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (i, accs_train[i], accs_test[i]))\n",
    "\n",
    "print(\"\\nAverage test accuracy: %f\" % np.mean(accs_test))\n",
    "print(\"Variance test accuracy: %f\" % np.var(accs_test))\n",
    "print(\"Min test accuracy: %f\" % np.min(accs_test))\n",
    "print(\"Max test accuracy: %f\" % np.max(accs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trL4zoRQ0AHJ"
   },
   "source": [
    "## 3. Least Squares with Normal Equations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for hyperparameters: Degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhESWEqZIiET"
   },
   "outputs": [],
   "source": [
    "# Model parameters for least squares\n",
    "#tuning parameters for each category\n",
    "degrees_candidates = [9,10,11,12,13,14]\n",
    "alpha = 0\n",
    "k_fold = 3\n",
    "par_degree, par_lambda, accu = select_parameters_least_squares(y,tX,degrees_candidates,alpha,k_fold,seed)\n",
    "par_degree, accu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcn-b3Ov0AHK"
   },
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "ZBfwZaXh0AHL",
    "outputId": "394c5bce-a0d5-4128-90d9-16295bf00a86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-228-752a77a919f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0macc_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleast_squares\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0maccs_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0maccs_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\1° Semester\\Machine Learning\\Projects\\higgs_boson_classification\\crossvalidation.py\u001b[0m in \u001b[0;36mcross_validation\u001b[1;34m(y, x, fun, k_indices, k, degrees, alpha, lambdas, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# compute weights using given method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlambdas\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\1° Semester\\Machine Learning\\Projects\\higgs_boson_classification\\methods.py\u001b[0m in \u001b[0;36mleast_squares\u001b[1;34m(y, tx)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mleast_squares\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;34m\"\"\"calculate the least squares solution.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_mse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmse\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msolve\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'DD->D'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'dd->d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Singular matrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "# Degree polynomial expansion\n",
    "#degrees = [8,11,9]\n",
    "degrees = [7,10,9,9]\n",
    "#degrees = [5,7,6,6]\n",
    "eta=[10,10,14,14]\n",
    "\n",
    "alpha = 0\n",
    "\n",
    "# Split data in k-fold\n",
    "k_fold = 3\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    print(k)\n",
    "    acc_train, acc_test = cross_validation(y, tX, least_squares, k_indices, k, degrees, alpha)\n",
    "    accs_train.append(acc_train)\n",
    "    accs_test.append(acc_test)\n",
    "    \n",
    "for i in range(len(accs_train)):\n",
    "    print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (i, accs_train[i], accs_test[i]))\n",
    "\n",
    "print(\"\\nAverage test accuracy: %f\" % np.mean(accs_test))\n",
    "print(\"Variance test accuracy: %f\" % np.var(accs_test))\n",
    "print(\"Min test accuracy: %f\" % np.min(accs_test))\n",
    "print(\"Max test accuracy: %f\" % np.max(accs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRNkS9Vt0AHP"
   },
   "source": [
    "## 4. Ridge regression with Normal Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FSx3D5s0AHQ"
   },
   "source": [
    "#### Search for hyperparameters: Lambdas, Degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pbx_ypfVIdS6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.001 3\n",
      "0.8551184141600728 0.8502109122990819\n",
      "10 0.001 3\n",
      "0.8557800998042513 0.8488599707755508\n",
      "10 0.01 3\n",
      "0.8524716715833586 0.8502660527694301\n",
      "10 0.01 3\n",
      "0.8544842987510683 0.84919081359764\n",
      "10 0.1 3\n",
      "0.8482258553665463 0.8458548151415731\n",
      "10 0.1 3\n",
      "0.8501557718287337 0.8462683686691848\n",
      "10 1.0 3\n",
      "0.8339169033111853 0.8323729701414353\n",
      "10 1.0 3\n",
      "0.8350748531884977 0.83253839155248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([10.0], [0.01], [3.0], [0.8502660527694301])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model parameters for ridge regression\n",
    "#tuning parameters for each category\n",
    "degrees_candidates = [10]\n",
    "alphas_candidates=[3]\n",
    "lambdas_candidates = np.logspace(-3,0,4)\n",
    "#lambdas_candidates=[1e-5]\n",
    "\n",
    "\n",
    "k_fold = 2\n",
    "par_degree, par_lambda, par_alpha, accu = select_parameters_ridge_regression(y,tX,degrees_candidates,lambdas_candidates,\n",
    "                                                                  alphas_candidates,k_fold,seed)\n",
    "par_degree, par_lambda, par_alpha, accu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNtdvgWo0AHW"
   },
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "2K8LmbWb0AHX",
    "outputId": "33fa584e-49d2-48eb-89fd-6ac9da428a61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.8433513734054936 0.840255361021444\n",
      "1\n",
      "0.8440233760935044 0.8395953583814335\n",
      "2\n",
      "0.843627374509498 0.8406753627014508\n",
      "0 - Training accuracy: 0.843351 / Test accuracy : 0.840255\n",
      "1 - Training accuracy: 0.844023 / Test accuracy : 0.839595\n",
      "2 - Training accuracy: 0.843627 / Test accuracy : 0.840675\n",
      "\n",
      "Average test accuracy: 0.840175\n",
      "Variance test accuracy: 0.000000\n",
      "Min test accuracy: 0.839595\n",
      "Max test accuracy: 0.840675\n"
     ]
    }
   ],
   "source": [
    "# Process data parameters\n",
    "#degrees = [8, 8, 10]\n",
    "degrees=[9,9,9]\n",
    "#alphas = [4.0, 5.0, 3.0]\n",
    "alpha=[3,3,3]\n",
    "\n",
    "# Model parameters\n",
    "#lambdas = [1e-06, 0.001, 0.01]\n",
    "lambdas=[0.00001,0.00001,0.00001]\n",
    "\n",
    "# Split data in k-fold\n",
    "k_fold = 3\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    print(k)\n",
    "    acc_train, acc_test = cross_validation_ridge_regression(y, tX, k_indices, k, lambdas, degrees, alphas)\n",
    "    accs_train.append(acc_train)\n",
    "    accs_test.append(acc_test)\n",
    "    \n",
    "for i in range(len(accs_train)):\n",
    "    print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (i, accs_train[i], accs_test[i]))\n",
    "\n",
    "print(\"\\nAverage test accuracy: %f\" % np.mean(accs_test))\n",
    "print(\"Variance test accuracy: %f\" % np.var(accs_test))\n",
    "print(\"Min test accuracy: %f\" % np.min(accs_test))\n",
    "print(\"Max test accuracy: %f\" % np.max(accs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0qlFWFL0AHb"
   },
   "source": [
    "## 5. Logistic Regression with Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uYY_UbE0AHc"
   },
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqdp4-eb0AHc",
    "outputId": "5eba52c4-27c6-461c-9865-61aadde2bd6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.997182550126146 0 /5000\n",
      "0.7524469806959074 1000 /5000\n",
      "0.4363734465688057 2000 /5000\n",
      "0.400023839876429 3000 /5000\n",
      "0.40076385746875537 4000 /5000\n",
      "10.371044956652037 0 /5000\n",
      "1.5550707519015254 1000 /5000\n",
      "0.661663323193932 2000 /5000\n",
      "0.5936779549816508 3000 /5000\n",
      "0.5260682969312651 4000 /5000\n",
      "8.442467521375363 0 /5000\n",
      "1.7929335626679517 1000 /5000\n",
      "0.7223707415043099 2000 /5000\n",
      "0.5914451124506169 3000 /5000\n",
      "0.5454690010169485 4000 /5000\n",
      "12.029170671306018 0 /5000\n",
      "2.0525746152729285 1000 /5000\n",
      "0.8818547205280977 2000 /5000\n",
      "0.6671236655053144 3000 /5000\n",
      "0.5709404738188759 4000 /5000\n",
      "6.689309726685983 0 /5000\n",
      "0.7984062586900572 1000 /5000\n",
      "0.4669079564079578 2000 /5000\n",
      "0.4200246548981903 3000 /5000\n",
      "0.4292098025507569 4000 /5000\n",
      "9.748515728107092 0 /5000\n",
      "1.2804452477863466 1000 /5000\n",
      "0.6366004683073873 2000 /5000\n",
      "0.5702327086476892 3000 /5000\n",
      "0.5406348712757687 4000 /5000\n",
      "10.207457083659229 0 /5000\n",
      "1.8709968020623324 1000 /5000\n",
      "0.8871537214879525 2000 /5000\n",
      "0.6549933484898737 3000 /5000\n",
      "0.6273568446088855 4000 /5000\n",
      "10.921340377430047 0 /5000\n",
      "2.2292933821924934 1000 /5000\n",
      "0.8149678070962392 2000 /5000\n",
      "0.6580696579333538 3000 /5000\n",
      "0.606312214919163 4000 /5000\n",
      "0 - Training accuracy: 0.781112 / Test accuracy : 0.782488\n",
      "1 - Training accuracy: 0.781568 / Test accuracy : 0.778112\n",
      "\n",
      "Average test accuracy: 0.780300\n",
      "Variance test accuracy: 0.000005\n",
      "Min test accuracy: 0.778112\n",
      "Max test accuracy: 0.782488\n"
     ]
    }
   ],
   "source": [
    "# Degree polynomial expansion\n",
    "degrees = [7,10,9,9]\n",
    "\n",
    "# Model parameters\n",
    "max_iters = 5000\n",
    "gamma = 0.005\n",
    "batch_size = 1\n",
    "\n",
    "# Split data in k-fold\n",
    "k_fold = 2\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    acc_train, acc_test = cross_validation(y, tX, logistic_regression, k_indices, k, batch_size=batch_size, \n",
    "                                           max_iters=max_iters, gamma=gamma, degrees=degrees)\n",
    "    accs_train.append(acc_train)\n",
    "    accs_test.append(acc_test)\n",
    "    \n",
    "for i in range(len(accs_train)):\n",
    "    print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (i, accs_train[i], accs_test[i]))\n",
    "\n",
    "print(\"\\nAverage test accuracy: %f\" % np.mean(accs_test))\n",
    "print(\"Variance test accuracy: %f\" % np.var(accs_test))\n",
    "print(\"Min test accuracy: %f\" % np.min(accs_test))\n",
    "print(\"Max test accuracy: %f\" % np.max(accs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGOLWOaT0AHg"
   },
   "source": [
    "## 6. Regularized Logistic Regression with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyOb7sDh0AHh"
   },
   "source": [
    "#### Optimal Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iy2RbgfS0AHh"
   },
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjGmRlLe0AHm"
   },
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nj7QHy7E0AHn"
   },
   "outputs": [],
   "source": [
    "# TO DO\n",
    "\n",
    "lambda_ = 0.001\n",
    "initial_w = np.random.random(tX.shape[1])\n",
    "batch_size = 1\n",
    "max_iters = 1000\n",
    "gamma = 0.1\n",
    "\n",
    "loss, weights = reg_logistic_regression(y, tX, lambda_, initial_w, batch_size,  max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPuY4BlP0AHr"
   },
   "source": [
    "# Prediction (file.run)\n",
    "by now the best accuracy predicted is through RIDGE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "8zP-dXnh0AHr"
   },
   "outputs": [],
   "source": [
    "# Split data in subsets corresponding to a jet value\n",
    "msks_jet_train = get_jet_masks(tX)\n",
    "msks_jet_test = get_jet_masks(tX_test)\n",
    "\n",
    "# Degree polynomial expansion\n",
    "degrees = [8,8,10]\n",
    "alphas = [4,5,3]\n",
    "# Ridge regression parameters for each subset\n",
    "lambdas = [1e-06, 0.001, 0.01]\n",
    "\n",
    "# Vector to store the final prediction\n",
    "y_pred = np.zeros(tX_test.shape[0])\n",
    "\n",
    "for idx in range(len(msks_jet_train)):\n",
    "    x_train = tX[msks_jet_train[idx]]\n",
    "    x_test = tX_test[msks_jet_test[idx]]\n",
    "    y_train = y[msks_jet_train[idx]]\n",
    "\n",
    "    # Pre-processing of data\n",
    "    x_train, x_test = process_data(x_train, x_test, alphas[idx])\n",
    "    # Trasform the data and add an intercepta\n",
    "    x_train, x_test = phi(x_train, x_test, degrees[idx])\n",
    "\n",
    "    loss, weights = ridge_regression(y_train, x_train, lambdas[idx])\n",
    "\n",
    "    y_test_pred = predict_labels(weights, x_test)\n",
    "\n",
    "    y_pred[msks_jet_test[idx]] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "caDm4rbc0AHx",
    "outputId": "3d109399-41cf-4a15-b840-a10ef1eecf00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 568238 test examples, 177764 are 1, i.e. the 0.3128337070030515 %\n"
     ]
    }
   ],
   "source": [
    "higgs = np.count_nonzero(y_pred==1)\n",
    "print(f'From {y_pred.shape[0]} test examples, {higgs} are 1, i.e. the {higgs/y_pred.shape[0]} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mfjj7aBa0AH5"
   },
   "source": [
    "#### Generate predictions and save ouput in csv format for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Ub5ITgmg0AH5"
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'data/RidgeRegression.csv' \n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_3W_bxL0AIA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "SuQONAGy0AH9"
   },
   "outputs": [],
   "source": [
    "y_pred1=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fs6Nkx-q0AIE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KoefpFkD0AIH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJimq_Yz0AIL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfJHyeRX0AIO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCbdi7wq0AIR"
   },
   "source": [
    "# OTHERS (old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXTtZSbs0AIS"
   },
   "source": [
    "### Umbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GimxSef0AIS"
   },
   "outputs": [],
   "source": [
    "higgs = np.count_nonzero(y==1)\n",
    "print(f'From {y.shape[0]} training examples, {higgs} are 1, i.e. the {higgs/y.shape[0]} %')\n",
    "\n",
    "# Random Over Sampling\n",
    "#tX, y = Random_Over_Sampling(tX, y)\n",
    "\n",
    "#higgs = np.count_nonzero(y==1)\n",
    "#print(f'Applying Random Over Sampling: \\nFrom {y.shape[0]} training examples, {higgs} are 1, i.e. the {higgs/y.shape[0]} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3hPd3D80AIX"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1KoJPkg50AIY"
   },
   "outputs": [],
   "source": [
    "tX, tX_test = process_data(tX, tX_test, add_constant_col=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yx3zjeX60AIe"
   },
   "source": [
    "# Cross Validation\n",
    "IDEA: insert CV in each of the methods above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFR2Y75w0AIf"
   },
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, regression_method, **args):\n",
    "    \"\"\"\n",
    "    Completes k-fold cross-validation using the regression method\n",
    "    passed as argument.\n",
    "    \"\"\"\n",
    "    # get k'th subgroup in test, others in train\n",
    "    msk_test = k_indices[k]\n",
    "    msk_train = np.delete(k_indices, (k), axis=0).ravel()\n",
    "\n",
    "    x_train = x[msk_train, :]\n",
    "    x_test = x[msk_test, :]\n",
    "    y_train = y[msk_train]\n",
    "    y_test = y[msk_test]\n",
    "\n",
    "    # data pre-processing\n",
    "    #x_train, x_test = process_data(x_train, x_test, True)\n",
    "\n",
    "    # compute weights using given method\n",
    "    loss, weights = regression_method(y=y_train, tx=x_train, **args)\n",
    "    \n",
    "    # predict output for train and test data\n",
    "    y_train_pred = predict_labels(weights, x_train)\n",
    "    y_test_pred = predict_labels(weights, x_test)\n",
    "    \n",
    "    \n",
    "    # compute accuracy for train and test data\n",
    "    acc_train = compute_accuracy(y_train_pred, y_train)\n",
    "    acc_test = compute_accuracy(y_test_pred, y_test)\n",
    "\n",
    "    return acc_train, acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSzxeArR0AIj",
    "outputId": "7efa3077-566c-45a4-d95b-d51c538dd74c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Training accuracy: 0.775480 / Test accuracy : 0.776096\n",
      "1 - Training accuracy: 0.775888 / Test accuracy : 0.774656\n",
      "\n",
      "Average test accuracy: 0.775376\n",
      "Variance test accuracy: 0.000001\n",
      "Min test accuracy: 0.774656\n",
      "Max test accuracy: 0.776096\n"
     ]
    }
   ],
   "source": [
    "regression_method = ridge_regression\n",
    "\n",
    "# Model parameters\n",
    "lambda_ = 0.0005\n",
    "\n",
    "# Split data in k-fold\n",
    "k_fold = 2\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    acc_train, acc_test = cross_validation(y, tX, k_indices, k, regression_method, lambda_=lambda_)\n",
    "    accs_train.append(acc_train)\n",
    "    accs_test.append(acc_test)\n",
    "    \n",
    "for i in range(len(accs_train)):\n",
    "    print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (i, accs_train[i], accs_test[i]))\n",
    "\n",
    "print(\"\\nAverage test accuracy: %f\" % np.mean(accs_test))\n",
    "print(\"Variance test accuracy: %f\" % np.var(accs_test))\n",
    "print(\"Min test accuracy: %f\" % np.min(accs_test))\n",
    "print(\"Max test accuracy: %f\" % np.max(accs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUHb8uzq0AHR"
   },
   "outputs": [],
   "source": [
    "# TO CHECK\n",
    "\n",
    "# To evaluate the best lambda that minimizes the test error\n",
    "loss, weights, best_lambda = cross_validation_ridge_regression(y,tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97-LOyA10AIp"
   },
   "outputs": [],
   "source": [
    "# Only for non logistic methods\n",
    "y_pred = predict_labels(weights, tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8VXKujj0AIw"
   },
   "outputs": [],
   "source": [
    "# Only for Logistic methods\n",
    "y_pred = sigmoid(tX_test@weights)\n",
    "y_pred[y_pred <0.5] = -1\n",
    "y_pred[y_pred > 0.5] = 1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
